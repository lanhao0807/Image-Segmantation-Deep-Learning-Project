{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sspfpn import SSPFPN, customized_loss\n",
    "import matrix as mt\n",
    "import prepareVOC12 as voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1171, 224, 224, 3)\n",
      "(293, 224, 224, 3)\n",
      "(1171, 224, 224, 3)\n",
      "(293, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "class_dict = voc.class_dict\n",
    "data_dir = \"./VOC12/train\"\n",
    "labels_dir = \"./VOC12/train_label\"\n",
    "\n",
    "x, y = voc.load_data(data_dir, labels_dir)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_contained(label_map):\n",
    "    print(\"Label map shape:\", label_map.shape)\n",
    "\n",
    "    # Reshape the label_map to a 2D array\n",
    "    label_map_2d = label_map.reshape(-1, 3)\n",
    "\n",
    "    # Find the unique color vectors in the label map\n",
    "    unique_colors = np.unique(label_map_2d, axis=0)\n",
    "    plt.imshow(label_map)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Unique color vectors in label map:\", unique_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to one_hot_maps\n",
    "\n",
    "y_train_onehot = []\n",
    "y_val_onehot = []\n",
    "\n",
    "for label_map in y_train:\n",
    "    one_hot_map = voc.label_to_onehot(label_map, class_dict)\n",
    "    y_train_onehot.append(one_hot_map)\n",
    "\n",
    "for label_map in y_val:\n",
    "    one_hot_map = voc.label_to_onehot(label_map, class_dict)\n",
    "    y_val_onehot.append(one_hot_map)\n",
    "\n",
    "y_train_onehot = np.array(y_train_onehot)\n",
    "y_val_onehot = np.array(y_val_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 52\n",
    "original_label_map = y_val[index]\n",
    "one_hot_map = y_val_onehot[index]\n",
    "converted_label_map = voc.onehot_to_label(one_hot_map, class_dict)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(original_label_map)\n",
    "axs[0].set_title('Original Label Map')\n",
    "axs[1].imshow(converted_label_map)\n",
    "axs[1].set_title('Converted Label Map')\n",
    "plt.show()\n",
    "# print(one_hot_map[90][200])\n",
    "# for i in range(len(one_hot_map)):\n",
    "#     for j in range(len(one_hot_map)):\n",
    "#         if sum(one_hot_map[i][j]) != 0:\n",
    "#             print(one_hot_map[i][j]) \n",
    "\n",
    "color_contained(original_label_map)\n",
    "color_contained(converted_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "model = SSPFPN(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "# epochs = 50\n",
    "# batch_size = 10\n",
    "# steps_per_epoch = len(x_train) // batch_size\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=2.5e-4, momentum=0.9, decay=5e-4)\n",
    "print(x_train[0].shape)\n",
    "\n",
    "\n",
    "print(np.array(mt.split_image_into_blocks(x_train[0]))[7][7].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train_onehot)).batch(5)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val_onehot)).batch(5)\n",
    "\n",
    "# Set the optimizer\n",
    "initial_learning_rate = 2.5e-4\n",
    "decay_rate = 0.9\n",
    "decay_steps = 300  # training size / batch size\n",
    "\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate, decay_steps, decay_rate, staircase=True)\n",
    "opt = SGD(learning_rate=lr_schedule, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.mixed_precision import global_policy, set_global_policy, Policy\n",
    "\n",
    "policy = Policy('mixed_float16')\n",
    "set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 50 epochs\n",
    "for epoch in range(50):\n",
    "    print(f\"Epoch {epoch + 1}/50\")\n",
    "\n",
    "    # Train\n",
    "    for batch_x, batch_y in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            batch_x = tf.cast(batch_x, tf.float32)\n",
    "            y_pred = model(batch_x, training=True)  \n",
    "            loss = customized_loss(batch_x, batch_y, y_pred)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Validate\n",
    "    val_losses = []\n",
    "    for batch_x, batch_y in val_dataset:\n",
    "        y_pred = model(batch_x, training=False)\n",
    "        loss = customized_loss(batch_x, batch_y, y_pred)\n",
    "        val_losses.append(loss.numpy())\n",
    "    val_loss = np.mean(val_losses)\n",
    "    print(f\"Validation loss: {val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
